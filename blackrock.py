# -*- coding: utf-8 -*-
"""BlackRock.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bsKN7lsYj6TLrQSmdcUc02uB4vjfJibp
"""

# Imports and Data Download
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.optimize import minimize
import os

# Tickers and date range
tickers = ['AAPL', 'MSFT', 'TSLA', 'JPM', 'GOOGL']
start_date = '2020-01-01'
end_date = '2024-12-31'

# Download adjusted close prices
data = yf.download(tickers, start=start_date, end=end_date, auto_adjust=False)
data = data['Adj Close']
data.dropna(inplace=True)
# Create 'data' directory
os.makedirs("data", exist_ok=True)
# Save raw data
data.to_csv("data/stock_data.csv")

# Daily Returns
returns = data.pct_change().dropna()

# Summary stats
print(returns.describe())

# Correlation heatmap
plt.figure(figsize=(8, 5))
sns.heatmap(returns.corr(), annot=True, cmap="coolwarm")
plt.title("Correlation of Daily Returns")
plt.show()

# Portfolio Optimization
mean_returns = returns.mean()
cov_matrix = returns.cov()

def portfolio_perf(weights):
    port_return = np.sum(weights * mean_returns) * 252
    port_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix * 252, weights)))
    sharpe = port_return / port_vol
    return port_return, port_vol, sharpe

def negative_sharpe(weights):
    return -portfolio_perf(weights)[2]

def constraint_sum(weights):
    return np.sum(weights) - 1

# Initial guess and bounds
num_assets = len(tickers)
init_guess = [1/num_assets] * num_assets
bounds = [(0, 1)] * num_assets
constraints = ({'type': 'eq', 'fun': constraint_sum})

opt = minimize(negative_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=constraints)
opt_weights = opt.x.round(4)
print(f"Optimal Weights:\n{dict(zip(tickers, opt_weights))}")

# Value at Risk
portfolio_returns = returns.dot(opt_weights)

# Parametric VaR (Gaussian)
conf_level = 0.95
z_score = abs(np.percentile(portfolio_returns, (1 - conf_level) * 100))
parametric_var = np.mean(portfolio_returns) - z_score * np.std(portfolio_returns)
print(f"Parametric VaR (95%): {round(parametric_var * 100, 2)}%")

# Historical VaR
historical_var = np.percentile(portfolio_returns, 5)
print(f"Historical VaR (5%): {round(historical_var * 100, 2)}%")

# Plot distribution
plt.figure(figsize=(7, 5))
sns.histplot(portfolio_returns, kde=True, bins=50)
plt.axvline(historical_var, color='red', linestyle='--', label='Historical VaR (5%)')
plt.title("Portfolio Daily Returns Distribution")
plt.legend()
plt.show()

# Simulate Market Shock
shock_returns = portfolio_returns.copy()
shock_returns.iloc[-10:] = shock_returns.iloc[-10:] - 0.02  # simulate 2% daily drop for last 10 days

plt.plot(portfolio_returns[-50:].cumsum(), label='Original')
plt.plot(shock_returns[-50:].cumsum(), label='Shocked', linestyle='--')
plt.title("Portfolio Cumulative Returns (With Shock)")
plt.legend()
plt.grid(True)
plt.show()

# Efficient Frontier (Monte Carlo Sim)
n_portfolios = 5000
results = np.zeros((3, n_portfolios))
weights_record = []

for i in range(n_portfolios):
    weights = np.random.random(num_assets)
    weights /= np.sum(weights)
    weights_record.append(weights)
    port_return, port_vol, sharpe = portfolio_perf(weights)
    results[0,i] = port_return
    results[1,i] = port_vol
    results[2,i] = sharpe

# Plot
plt.scatter(results[1,:], results[0,:], c=results[2,:], cmap='viridis')
plt.colorbar(label='Sharpe Ratio')
opt_ret, opt_vol, _ = portfolio_perf(opt_weights)
plt.scatter(opt_vol, opt_ret, marker='*', color='r', s=200, label='Optimal Portfolio')
plt.xlabel('Volatility (Std Dev)')
plt.ylabel('Expected Return')
plt.title("Efficient Frontier")
plt.legend()
plt.show()

